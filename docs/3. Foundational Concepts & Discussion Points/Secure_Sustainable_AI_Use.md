## ðŸ”’ 1:15â€“1:30 â€” Secure & Sustainable AI Use

### ðŸŒŸ Purpose

Ground the seminar in responsible use. Provide participants with confidence about what they *can* do now without risking sensitive data, and how to think long-term about integrating AI in secure, governed ways.

---

### ðŸ“„ Framing Statement

> â€œEven if the AI gets the right answer, if you use the wrong data or tool, it can create serious risk. Letâ€™s talk about whatâ€™s safe, whatâ€™s smart, and whatâ€™s sustainable in your setting.â€

---

## ðŸ” Key Principles

### Core AI Implementation Principles

1. **People-first Design**
   AI should enhance human capabilities, not replace human judgment. TSOs remain central to teaching support delivery.

2. **Responsible and Ethical Use of AI**
   Consider the impact on students, staff, and academic integrity. Ensure transparency in AI-assisted processes.

3. **Secure and Responsible Design**
   Align with Curtin's IT security policies and TEQSA compliance requirements. Protect student data and privacy.

### Practical Safety Guidelines

1. **Use mock or public data in all experiments**
   Especially in exploratory or non-integrated tools (e.g., ChatGPT, Claude). Never use real student data outside secure systems.

2. **Assume anything entered into a public AI chat is public**
   Unless you *know* the tool offers enterprise privacy, don't paste student-identifiable or sensitive university information.

3. **Use your secure platforms for sensitive work**
   Copilot inside Microsoft 365 is the ONLY approved tool for university data. Your data stays in your tenant and isn't used to train models.

4. **Prototype in chat tools, deploy in secure environments**
   Test prompts with mock data in ChatGPT, then migrate your workflow to secure Copilot or approved university systems.

5. **Governance is a team sport**
   Involve your IT/security leads and Teaching & Learning committee when formalising AI use. Keep logs, version prompts, and review how tools access data.

---

# ðŸ¤– AI Tools: Whatâ€™s Under the Hood?

## 1. What is Copilot / ChatGPT?
- LLMs trained to predict useful text.
- Copilot runs inside M365 tools.
- ChatGPT is public-facing unless restricted.

## 2. What is Prompt Engineering?
- Structure your input to guide output.
- CRAFT = Context, Role, Action, Format, Task.

## 3. What Are Agents?
- Tools that reason + act using steps (e.g. AutoGPT).
- Not used directly in Copilot, but conceptually similar.

## 4. Key Concepts
- Context Window: How much AI can consider at once.
- Temperature: Randomness/creativity setting.
- Not â€œthinkingâ€ â€” just predicting.

## 5. Security & Risk
- Copilot: Internal to your M365 tenant.
- ChatGPT: Avoid client-sensitive data unless secured.
- Always verify AI output.

## 6. What are MCPs?
- â€œModel Context Protocolâ€
- An open protocol that lets AI assistants securely connect to external data sources and tools.




---

## ðŸš§ Platform Governance Comparison

| Tool             | Use Case                     | Governance Notes                                                    |
| ---------------- | ---------------------------- | ------------------------------------------------------------------- |
| **Copilot (M365)**| Primary tool for university work | âœ… APPROVED for internal docs and student data. Educational license. |
| **ChatGPT**      | Personal exploration only    | âŒ NOT for university data. Personal learning with mock data only.   |
| **Claude**       | Personal exploration only    | âŒ NOT for university data. Personal learning with mock data only.   |
| **Gemini**       | Personal exploration only    | âŒ NOT for university data. Personal learning with mock data only.   |
| **Libre Chat**   | Future possibility           | ðŸ”„ Under review by IT (Brenton/Matt). Not yet approved.            |

---

## ðŸš€ Strategy Summary: Prompt, Process, Protect

> 1. **Prompt It** â€” Use AI chat to test your thinking, summarise ideas, and shape workflows.
> 2. **Process It** â€” Move successful chains into tools like Copilot, n8n, or Zapier.
> 3. **Protect It** â€” When itâ€™s sensitive or client-facing, work within secure systems.

---

## ðŸš¶ What to Say if Asked: "Can we use this for real student data?"

> "Yes, but only in tools governed by Curtin's enterprise environment â€” like Copilot in Microsoft 365. You can prototype freely in public AI with mock data, but never use real student data outside secure university systems."

---

## ðŸ› Key Takeaway

> "AI is only as smart as your context â€” and only as safe as your systems. Microsoft Copilot is our approved tool for university work. Other AI tools are for personal exploration only."

